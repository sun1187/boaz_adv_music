{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f093f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ac7edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song id</th>\n",
       "      <th>곡 제목</th>\n",
       "      <th>가수</th>\n",
       "      <th>tag count</th>\n",
       "      <th>tag max</th>\n",
       "      <th>emotion max</th>\n",
       "      <th>곡 세부 장르 리스트</th>\n",
       "      <th>발매일</th>\n",
       "      <th>앨범 명</th>\n",
       "      <th>앨범 ID</th>\n",
       "      <th>...</th>\n",
       "      <th>좋아요수</th>\n",
       "      <th>어제순위</th>\n",
       "      <th>댓글1</th>\n",
       "      <th>댓글2</th>\n",
       "      <th>댓글3</th>\n",
       "      <th>댓글4</th>\n",
       "      <th>댓글5</th>\n",
       "      <th>1차 가공</th>\n",
       "      <th>2차 가공</th>\n",
       "      <th>3차 가공</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1890</td>\n",
       "      <td>모든게 지나면</td>\n",
       "      <td>화랑</td>\n",
       "      <td>{'뮤지컬': 1, '사랑': 1}</td>\n",
       "      <td>['뮤지컬', '사랑']</td>\n",
       "      <td>['경쾌한', '행복한']</td>\n",
       "      <td>['GN2902', 'GN1501', 'GN1507', 'GN2901']</td>\n",
       "      <td>20110621</td>\n",
       "      <td>뮤지컬 화랑 OST Vol.2</td>\n",
       "      <td>1315555</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...</td>\n",
       "      <td>이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...</td>\n",
       "      <td>['이', '모든', '것', '다', '지나가다', '또', '시간', '흐르다'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2491</td>\n",
       "      <td>You Brought A New Kind Of Love To Me</td>\n",
       "      <td>Ella Fitzgerald</td>\n",
       "      <td>{'연말': 1, '새해': 1}</td>\n",
       "      <td>['연말', '새해']</td>\n",
       "      <td>['행복한']</td>\n",
       "      <td>['GN1701']</td>\n",
       "      <td>20180817</td>\n",
       "      <td>Ella Swings Lightly (Expanded Edition)</td>\n",
       "      <td>5644325</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>['없다']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   song id                                  곡 제목               가수  \\\n",
       "0     1890                               모든게 지나면               화랑   \n",
       "1     2491  You Brought A New Kind Of Love To Me  Ella Fitzgerald   \n",
       "\n",
       "             tag count        tag max     emotion max  \\\n",
       "0  {'뮤지컬': 1, '사랑': 1}  ['뮤지컬', '사랑']  ['경쾌한', '행복한']   \n",
       "1   {'연말': 1, '새해': 1}   ['연말', '새해']         ['행복한']   \n",
       "\n",
       "                                곡 세부 장르 리스트       발매일  \\\n",
       "0  ['GN2902', 'GN1501', 'GN1507', 'GN2901']  20110621   \n",
       "1                                ['GN1701']  20180817   \n",
       "\n",
       "                                     앨범 명    앨범 ID  ... 좋아요수 어제순위 댓글1 댓글2 댓글3  \\\n",
       "0                        뮤지컬 화랑 OST Vol.2  1315555  ...   25   없음  없음  없음  없음   \n",
       "1  Ella Swings Lightly (Expanded Edition)  5644325  ...    1   없음  없음  없음  없음   \n",
       "\n",
       "  댓글4  댓글5                                              1차 가공  \\\n",
       "0  없음   없음  이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...   \n",
       "1  없음   없음                                                 없음   \n",
       "\n",
       "                                               2차 가공  \\\n",
       "0  이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...   \n",
       "1                                                 없음   \n",
       "\n",
       "                                               3차 가공  \n",
       "0  ['이', '모든', '것', '다', '지나가다', '또', '시간', '흐르다'...  \n",
       "1                                             ['없다']  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_all_info = pd.read_csv('../Data/selected_song_all_info.csv')\n",
    "song_all_info.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a629af90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['song id', '곡 제목', '가수', 'tag count', 'tag max', 'emotion max',\n",
       "       '곡 세부 장르 리스트', '발매일', '앨범 명', '앨범 ID', '아티스트 ID 리스트', '곡 장르 리스트',\n",
       "       '아티스트 리스트', '대분류str', '소분류str', 'tags', '우울한', '울고싶은', '긴장되는', '무서운',\n",
       "       '잔잔한', '행복한', '경쾌한', '편안한', '원가사', '좋아요수', '어제순위', '댓글1', '댓글2', '댓글3',\n",
       "       '댓글4', '댓글5', '1차 가공', '2차 가공', '3차 가공'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_all_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca9875f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_all_info_lyrics = song_all_info[song_all_info['2차 가공'] != '없음']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a751892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_all_info_lyrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013aebae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2차 가공</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아직 열어보지 말아요 호기심이 생겨도 떨어트리 지도 말아요 그럼 나는 깨져버릴 테니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>너를 맘에 담고 나는 눈을 감고 우리의 추억을 떠올리며 살아 항상 행복했던 우리 기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>흰 꽃은 밤에 아름답단 이유를 내게도 가르쳐줄 순 없소 이대로 날 잡아둘 뿐인지 흰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>나 기도할게 저 하늘에도 그대가 나의 기억 간직하도록 널 위해 불러 주었던 그 노래...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>거짓말하고 당신의 걱정이 내려오지 않아서 너무 어리 석지 마십시오 나는 처음으로 미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>홀로 카페의 문을 열어 본다 쓰디쓴 커피 한잔 시켜 본 다다 읽지 못할 책을 꺼내고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Oh shit 너무나도 너무나도 두리 뚱뚱한 너네 엄마 아무 잘못 없는 내가 뭐가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>네가 어떤 대학을 나왔는지 어떤 집안인지도 관심이 없어온 그렇게 자랑스러우면 얼굴에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>방금 L에서 검은 페라리 하우스를 샀다 나는 기억을 돌볼 것이라고 말할 것이지만 나...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  2차 가공\n",
       "0     이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...\n",
       "2     아직 열어보지 말아요 호기심이 생겨도 떨어트리 지도 말아요 그럼 나는 깨져버릴 테니...\n",
       "4     너를 맘에 담고 나는 눈을 감고 우리의 추억을 떠올리며 살아 항상 행복했던 우리 기...\n",
       "5     흰 꽃은 밤에 아름답단 이유를 내게도 가르쳐줄 순 없소 이대로 날 잡아둘 뿐인지 흰...\n",
       "6     나 기도할게 저 하늘에도 그대가 나의 기억 간직하도록 널 위해 불러 주었던 그 노래...\n",
       "...                                                 ...\n",
       "1068  거짓말하고 당신의 걱정이 내려오지 않아서 너무 어리 석지 마십시오 나는 처음으로 미...\n",
       "1071  홀로 카페의 문을 열어 본다 쓰디쓴 커피 한잔 시켜 본 다다 읽지 못할 책을 꺼내고...\n",
       "1072  Oh shit 너무나도 너무나도 두리 뚱뚱한 너네 엄마 아무 잘못 없는 내가 뭐가 ...\n",
       "1073  네가 어떤 대학을 나왔는지 어떤 집안인지도 관심이 없어온 그렇게 자랑스러우면 얼굴에...\n",
       "1075  방금 L에서 검은 페라리 하우스를 샀다 나는 기억을 돌볼 것이라고 말할 것이지만 나...\n",
       "\n",
       "[704 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.DataFrame(song_all_info_lyrics['2차 가공'])\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077d239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77884643",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.columns=['ori_index', 'lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285b6fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori_index</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>아직 열어보지 말아요 호기심이 생겨도 떨어트리 지도 말아요 그럼 나는 깨져버릴 테니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>너를 맘에 담고 나는 눈을 감고 우리의 추억을 떠올리며 살아 항상 행복했던 우리 기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>흰 꽃은 밤에 아름답단 이유를 내게도 가르쳐줄 순 없소 이대로 날 잡아둘 뿐인지 흰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>나 기도할게 저 하늘에도 그대가 나의 기억 간직하도록 널 위해 불러 주었던 그 노래...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>1068</td>\n",
       "      <td>거짓말하고 당신의 걱정이 내려오지 않아서 너무 어리 석지 마십시오 나는 처음으로 미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1071</td>\n",
       "      <td>홀로 카페의 문을 열어 본다 쓰디쓴 커피 한잔 시켜 본 다다 읽지 못할 책을 꺼내고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>1072</td>\n",
       "      <td>Oh shit 너무나도 너무나도 두리 뚱뚱한 너네 엄마 아무 잘못 없는 내가 뭐가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1073</td>\n",
       "      <td>네가 어떤 대학을 나왔는지 어떤 집안인지도 관심이 없어온 그렇게 자랑스러우면 얼굴에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1075</td>\n",
       "      <td>방금 L에서 검은 페라리 하우스를 샀다 나는 기억을 돌볼 것이라고 말할 것이지만 나...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ori_index                                             lyrics\n",
       "0            0  이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...\n",
       "1            2  아직 열어보지 말아요 호기심이 생겨도 떨어트리 지도 말아요 그럼 나는 깨져버릴 테니...\n",
       "2            4  너를 맘에 담고 나는 눈을 감고 우리의 추억을 떠올리며 살아 항상 행복했던 우리 기...\n",
       "3            5  흰 꽃은 밤에 아름답단 이유를 내게도 가르쳐줄 순 없소 이대로 날 잡아둘 뿐인지 흰...\n",
       "4            6  나 기도할게 저 하늘에도 그대가 나의 기억 간직하도록 널 위해 불러 주었던 그 노래...\n",
       "..         ...                                                ...\n",
       "699       1068  거짓말하고 당신의 걱정이 내려오지 않아서 너무 어리 석지 마십시오 나는 처음으로 미...\n",
       "700       1071  홀로 카페의 문을 열어 본다 쓰디쓴 커피 한잔 시켜 본 다다 읽지 못할 책을 꺼내고...\n",
       "701       1072  Oh shit 너무나도 너무나도 두리 뚱뚱한 너네 엄마 아무 잘못 없는 내가 뭐가 ...\n",
       "702       1073  네가 어떤 대학을 나왔는지 어떤 집안인지도 관심이 없어온 그렇게 자랑스러우면 얼굴에...\n",
       "703       1075  방금 L에서 검은 페라리 하우스를 샀다 나는 기억을 돌볼 것이라고 말할 것이지만 나...\n",
       "\n",
       "[704 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d0fee",
   "metadata": {},
   "source": [
    "# 1) Funnel tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d12f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='kykim/funnel-kor-base', vocab_size=42000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '<sep>', 'pad_token': '<pad>', 'cls_token': '<cls>', 'mask_token': '<mask>'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# funnel: https://github.com/kiyoungkim1/LMkor\n",
    "from transformers import FunnelTokenizerFast, FunnelModel\n",
    "tokenizer_funnel = FunnelTokenizerFast.from_pretrained(\"kykim/funnel-kor-base\")\n",
    "tokenizer_funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05171979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts = [tokenizer_funnel.tokenize(s) for s in new['lyrics']]\n",
    "len(tokenized_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31eceee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "## 중복인가? 위랑?\n",
    "max_words = 1500\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(tokenized_texts)\n",
    "X_train_sequence = tokenizer.texts_to_sequences(tokenized_texts)\n",
    "\n",
    "max_len = max(len(l) for l in tokenized_texts)\n",
    "X_train_sequence = pad_sequences(X_train_sequence, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "432302ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "11327\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_sequence))\n",
    "print(len(tokenizer.index_word) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 1번)\n",
    "import tensorflow as tf\n",
    "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool1D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, LSTM, GlobalMaxPooling1D, Dropout, Conv1D, Bidirectional\n",
    "from keras.models import Sequential, load_model, save_model\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.index_word) + 1\n",
    "\n",
    "inputs = Sequential([\n",
    "    Input(shape=(max_len,), dtype='int32'),\n",
    "    Embedding(VOCAB_SIZE, 1000),\n",
    "    Dense(500, activatipn='relu'),\n",
    "    Dense(320, activatipn='relu'),\n",
    "    Dense(80, activatipn='relu'),\n",
    "    Dense(2, activatipn='relu'),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7be6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(tokenizer.index_word) + 1\n",
    "input_e = Input(shape=(max_len,), dtype='int32')\n",
    "visible = Embedding(VOCAB_SIZE, 1000)(input_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0648d1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11327\n",
      "1178\n"
     ]
    }
   ],
   "source": [
    "print(max_len)\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ee308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7d5f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/nnlm-ko-dim50/2'.\n",
      "INFO:absl:Downloading https://tfhub.dev/google/nnlm-ko-dim50/2: 80.00MB\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/nnlm-ko-dim50/2, Total size: 182.29MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/nnlm-ko-dim50/2'.\n",
      "2021-11-28 10:29:44.605238: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "###### 2번)\n",
    "#https://stackoverflow.com/questions/50236117/scraping-ssl-certificate-verify-failed-error-for-http-en-wikipedia-org\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "#embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "embedding = \"https://tfhub.dev/google/nnlm-ko-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a9216b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori_index</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>아직 열어보지 말아요 호기심이 생겨도 떨어트리 지도 말아요 그럼 나는 깨져버릴 테니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>너를 맘에 담고 나는 눈을 감고 우리의 추억을 떠올리며 살아 항상 행복했던 우리 기...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ori_index                                             lyrics\n",
       "0          0  이 모든 것이 다 지나가고 또 시간이 흐르고 나면 그때는 모든 게 아무것도 아닌 일...\n",
       "1          2  아직 열어보지 말아요 호기심이 생겨도 떨어트리 지도 말아요 그럼 나는 깨져버릴 테니...\n",
       "2          4  너를 맘에 담고 나는 눈을 감고 우리의 추억을 떠올리며 살아 항상 행복했던 우리 기..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f044cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.convert_to_tensor(new['lyrics'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "254e4860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 50), dtype=float32, numpy=\n",
       "array([[-0.19477855, -0.27582827, -0.20566653, -0.15327093,  0.57651126,\n",
       "        -0.4887043 ,  0.07854708, -0.50991964,  0.56739026,  0.31358808,\n",
       "         0.0434729 ,  0.3943373 , -0.5391527 ,  0.12588201,  0.1785739 ,\n",
       "        -0.22129142,  0.14705741,  0.18217263,  0.7379711 ,  0.29651603,\n",
       "         0.07402343,  0.4880862 ,  0.07329948,  0.05746513, -0.09860269,\n",
       "        -0.00261875, -0.6428524 , -0.7261156 ,  0.20309393, -0.11012473,\n",
       "         0.00900661, -0.00455079,  0.517931  ,  0.34816816, -0.2782427 ,\n",
       "        -0.06874816, -0.12072624, -0.25421253, -0.14863586,  0.18550904,\n",
       "         0.19681807,  0.33325413, -0.46237522, -0.10281283, -0.5763611 ,\n",
       "        -0.3024838 , -0.09411166, -0.1717179 , -0.13585027, -0.0742765 ],\n",
       "       [-0.38620946,  0.06556798, -0.43418127, -0.7664781 ,  0.24345705,\n",
       "        -1.002323  ,  0.7893328 , -0.5834687 ,  0.6004187 ,  0.8544621 ,\n",
       "         0.39782307,  0.5580107 , -1.117086  , -0.2279905 ,  1.4235936 ,\n",
       "        -0.2504578 ,  0.12823687,  0.0312358 ,  0.31325352,  0.39819708,\n",
       "         0.16610722,  0.6132904 ,  0.05496538, -0.5090875 ,  0.09636863,\n",
       "        -0.05966898, -0.5777851 , -0.5795339 ,  0.71529937,  0.00765718,\n",
       "         0.40935728, -0.32514772,  0.6150938 ,  0.6001158 ,  0.16742429,\n",
       "        -0.35167438,  0.5434122 ,  0.11347217,  0.15505454,  0.03161246,\n",
       "        -0.19549707,  0.5821569 , -0.8733322 ,  0.3567223 , -0.22960627,\n",
       "        -0.24045883, -0.54751575,  0.03626971, -0.50401807,  0.41478914],\n",
       "       [-0.3071928 , -0.06845456, -0.24260478, -0.3856574 ,  0.5529673 ,\n",
       "        -0.7980116 ,  0.32283232, -0.805092  ,  0.5907012 ,  0.66301   ,\n",
       "         0.05038706,  0.2993522 , -0.5778063 ,  0.35323134,  0.7026034 ,\n",
       "        -0.4046614 , -0.08196928,  0.37291113,  0.54719055,  0.4825364 ,\n",
       "         0.1658916 ,  0.32542378, -0.03944378, -0.06259173,  0.19073614,\n",
       "         0.21553409, -0.24533637, -0.46255025,  0.2504426 ,  0.19817649,\n",
       "        -0.1502729 , -0.10344838,  0.71730113,  0.11083476,  0.0709122 ,\n",
       "        -0.401609  , -0.1285384 ,  0.05737007, -0.07651111,  0.15084662,\n",
       "        -0.16525792,  0.288222  , -0.5586461 , -0.11221428, -0.2395505 ,\n",
       "        -0.34259373, -0.45569628,  0.42775416, -0.53793573,  0.16820604]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_layer(new['lyrics'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ea422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b7af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78faca62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cbe580",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2d/k1h9bjt9385d884qrqvzk1880000gn/T/ipykernel_2567/3765158741.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# define encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0minput_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "##### 3번\n",
    "#https://machinelearningmastery.com/autoencoder-for-classification/\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, Embedding\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define encoder\n",
    "VOCAB_SIZE = len(tokenizer.index_word) + 1\n",
    "input_e = Input(shape=(max_len,), dtype='int32')\n",
    "visible = Embedding(VOCAB_SIZE, 1000)(input_e)\n",
    "#visible = Input(shape=(n_inputs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbbb4b6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <keras.layers.embeddings.Embedding object at 0x7f84afe81880>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2d/k1h9bjt9385d884qrqvzk1880000gn/T/ipykernel_61552/4053316814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# encoder level 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Inputs to a layer should be tensors. Got: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.layers.embeddings.Embedding object at 0x7f84afe81880>"
     ]
    }
   ],
   "source": [
    "# encoder level 1\n",
    "e = Dense(500)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# encoder level 2\n",
    "e = Dense(80)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# bottleneck\n",
    "#n_bottleneck = round(float(2) / 2.0)\n",
    "bottleneck = Dense(2)(e)\n",
    "\n",
    "# define decoder, level 1\n",
    "d = Dense(80)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# decoder level 2\n",
    "d = Dense(500)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# decoder level 3\n",
    "d = Dense(1000)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# decoder level 4\n",
    "d = Dense(VOCAB_SIZE)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# output layer\n",
    "output = Dense(max_len, activation='softmax')(d)\n",
    "\n",
    "# define autoencoder model\n",
    "model = Model(inputs=input_e, outputs=output)\n",
    "\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "#model.compile(optimizer='adam', loss='rmse')\n",
    "\n",
    "# plot the autoencoder\n",
    "#plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train_sequence, X_train_sequence, epochs=50,\n",
    "                    batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f89f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=input_e, outputs=bottleneck)\n",
    "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
    "# save the encoder to file\n",
    "#encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd6ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dacf77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b15ab4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 475, in call\n        raise NotImplementedError('When subclassing the `Model` class, you should '\n\n    NotImplementedError: Exception encountered when calling layer \"auto_encoders_1\" (type AutoEncoders).\n    \n    When subclassing the `Model` class, you should implement a `call()` method.\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(32, 1178), dtype=int32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2d/k1h9bjt9385d884qrqvzk1880000gn/T/ipykernel_61552/1533673335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m history = auto_encoder.fit(\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mX_train_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mX_train_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 475, in call\n        raise NotImplementedError('When subclassing the `Model` class, you should '\n\n    NotImplementedError: Exception encountered when calling layer \"auto_encoders_1\" (type AutoEncoders).\n    \n    When subclassing the `Model` class, you should implement a `call()` method.\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(32, 1178), dtype=int32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "###### 4번)\n",
    "class AutoEncoders(Model):\n",
    "    def __init__(self, output_units):\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential(\n",
    "            [\n",
    "              Dense(32, activation=\"relu\"),\n",
    "              Dense(16, activation=\"relu\"),\n",
    "              Dense(2, activation=\"relu\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = Sequential(\n",
    "            [\n",
    "              Dense(16, activation=\"relu\"),\n",
    "              Dense(32, activation=\"relu\"),\n",
    "              Dense(output_units, activation=\"sigmoid\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def call(self, inputs):\n",
    "    encoded = self.encoder(inputs)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "  \n",
    "auto_encoder = AutoEncoders(len(X_train_sequence))\n",
    "\n",
    "auto_encoder.compile(\n",
    "    loss='mae',\n",
    "    metrics=['mae'],\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "history = auto_encoder.fit(\n",
    "    X_train_sequence, \n",
    "    X_train_sequence, \n",
    "    epochs=15, \n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d395bb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66564f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
